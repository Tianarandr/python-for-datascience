{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA QDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNv/kDBV/QMWeS8xcOOW4Oc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tianarandr/python-for-datascience/blob/master/LDA_QDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FONCTION MATRICE DE CONFUSION, PRECISION, RAPPEL, F-MESURE\n",
        "import numpy as np\n",
        "#fonction sous Python qui permet de calculer la matrice de confusion √† partir de deux vecteurs ùë¶ et y_estime\n",
        "def comp_confmat(actuel, predicted):\n",
        "    classes = np.unique(actuel) # extraire les differentes classes\n",
        "    matrix = np.zeros((len(classes), len(classes))) # initializer une matrice avec des zeros\n",
        "    \n",
        "    for i in range(len(classes)):\n",
        "        for j in range(len(classes)):\n",
        "            matrix[i, j] = np.sum((actuel == classes[i]) & (predicted == classes[j]))\n",
        "\n",
        "    return matrix\n",
        "\n",
        "# une fonction qui calcule la pr√©cision globale.\n",
        "def precision_globale(matriceDeConfusion):\n",
        "    (m,n) = matriceDeConfusion.shape\n",
        "    somme = matriceDeConfusion.sum()\n",
        "    P = 0\n",
        "    \n",
        "    somme_par_row_p = 0\n",
        "    precision_classe_arr = []\n",
        "    somme_par_row = matriceDeConfusion.sum(1)\n",
        "    \n",
        "    \n",
        "    for row in range(m):\n",
        "        for col in range(n):\n",
        "            if row == col:\n",
        "                P += matriceDeConfusion[row][col]\n",
        "                somme_par_row_p += matriceDeConfusion[row][col]\n",
        "        \n",
        "        precision_classe =  somme_par_row_p/somme_par_row[row]\n",
        "        precision_classe_arr.append(precision_classe)\n",
        "        somme_par_row_p = 0\n",
        "    \n",
        "    precision_globale = P/somme\n",
        "    return precision_globale\n",
        "\n",
        "# une fonction qui permet de calculer le rappel globale\n",
        "def rappel_globale(matriceDeConfusion):\n",
        "    (m,n) = matriceDeConfusion.shape\n",
        "    somme = matriceDeConfusion.sum()\n",
        "    P = 0\n",
        "    \n",
        "    somme_par_col = 0\n",
        "    rappel_classe_arr = []\n",
        "    somme_par_col = matriceDeConfusion.sum(0)\n",
        "    \n",
        "    for col in range(n):\n",
        "        for row in range(m):\n",
        "            if row == col:\n",
        "                P += matriceDeConfusion[row][col]\n",
        "                VP = matriceDeConfusion[row][col]\n",
        "        \n",
        "        rappel_classe =  VP/somme_par_col[col]\n",
        "        rappel_classe_arr.append(rappel_classe)\n",
        "        somme_par_row_p = 0\n",
        "    \n",
        "    rappel_globale = P/somme\n",
        "    return rappel_globale\n",
        "\n",
        "# une fonction pour calculer la F-mesure globale.\n",
        "def f_mesure_globale(matrice_conf):\n",
        "    precision = precision_globale(matrice_conf)\n",
        "    rappel = rappel_globale(matrice_conf)\n",
        "    return 2 * ((precision * rappel)/ (precision + rappel))\n",
        "\n"
      ],
      "metadata": {
        "id": "5tcvR4PALKJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, f1_score, recall_score, accuracy_score\n",
        "from sklearn import datasets\n",
        "from numpy.random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from numpy.linalg import multi_dot, inv, det\n",
        "\n",
        "\n",
        "\n",
        "def LDA_ALGO(X, y_train):\n",
        "    classes = list(np.unique(y_train)) \n",
        "    estimates = [] \n",
        "    for c in classes:\n",
        "        estimate = []\n",
        "        estimate.append(c)\n",
        "        indices_of_rows = np.where(np.isin(y_train,c))\n",
        "        X_train_subset = X[indices_of_rows]\n",
        "        pi = float(len(X_train_subset))/float(len(X))\n",
        "        estimate.append(pi)\n",
        "        mean = (np.sum(X_train_subset,axis=0) / float(len(X_train_subset))).reshape(-1,1)\n",
        "        estimate.append(mean)\n",
        "        def take_cov(row,mean):\n",
        "            return (row.reshape(-1,1) - mean).dot((row.reshape(-1,1) - mean).T)\n",
        "        variance = (1./(len(X_train_subset) - len(classes))) * (sum([take_cov(row,mean) for row in X_train_subset]))\n",
        "        estimate.append(np.absolute(variance))\n",
        "        estimates.append(tuple(estimate))\n",
        "    variance = sum([estimate[3] for estimate in estimates])\n",
        "    variance_estimate = variance\n",
        "    probabilities = []\n",
        "    for estimate in estimates:\n",
        "        pi = estimate[1]\n",
        "        mean = estimate[2]\n",
        "        sigma_inv = inv(variance_estimate) \n",
        "        prob = multi_dot([X,sigma_inv,mean]) - (.5 * multi_dot([mean.T,sigma_inv,mean])) + np.log(pi)\n",
        "        probabilities.append(prob)\n",
        "    indices_of_highest_prob = np.argmax(np.concatenate(probabilities,axis=1),axis=1)\n",
        "\n",
        "    def predict_class(index):\n",
        "        return estimates[index][0] #l'indexe 0 de estimates contient la classe\n",
        "    predict_class_vec = np.vectorize(predict_class)\n",
        "    predictions = predict_class_vec(indices_of_highest_prob)\n",
        "    return predictions\n",
        "\n",
        "def QDA_ALGO(X,y_train):\n",
        "    classes = list(np.unique(y_train)) \n",
        "    estimates = [] \n",
        "    for c in classes:\n",
        "        estimate = []\n",
        "        estimate.append(c)\n",
        "        indices_of_rows = np.where(np.isin(y_train,c))\n",
        "        X_train_subset = X[indices_of_rows]\n",
        "        pi = float(len(X_train_subset))/float(len(X))\n",
        "        estimate.append(pi)\n",
        "        mean = (np.sum(X_train_subset,axis=0) / float(len(X_train_subset))).reshape(-1,1)\n",
        "        estimate.append(mean)\n",
        "        def take_cov(row,mean):\n",
        "            return (row.reshape(-1,1) - mean).dot((row.reshape(-1,1) - mean).T)\n",
        "        variance = (1./(len(X_train_subset) - len(classes))) * (sum([take_cov(row,mean) for row in X_train_subset]))\n",
        "        estimate.append(np.absolute(variance))\n",
        "        estimates.append(tuple(estimate))\n",
        "    variance = sum([estimate[3] for estimate in estimates])\n",
        "    probabilities = []\n",
        "    for estimate in estimates:\n",
        "        pi = estimate[1]\n",
        "        mean = estimate[2]\n",
        "        variance = estimate[3]\n",
        "        log_variance = np.log(variance)\n",
        "        sigma_inv = inv(log_variance)  \n",
        "        probs = []\n",
        "        for row in X:\n",
        "            x = row.reshape(-1,1)\n",
        "            prob = (-.5 * multi_dot([(x-mean).T,(sigma_inv),(x-mean)])[0][0]) - (.5 * np.log(np.absolute(det(log_variance)))) + np.log(pi)\n",
        "            probs.append(prob)\n",
        "        probabilities.append(np.array(probs).reshape(-1,1))\n",
        "    indices_of_highest_prob = np.argmax(np.concatenate(probabilities, axis=1), axis=1)\n",
        "    \n",
        "    def predict_class(index):\n",
        "        return estimates[index][0] \n",
        "    predict_class_vec = np.vectorize(predict_class)\n",
        "    predictions = predict_class_vec(indices_of_highest_prob)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "JEcWfeuVfcRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    iris = datasets.load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=5)\n",
        "    # LDA SANS BIBLIOTHEQUE\n",
        "    results = LDA_ALGO(X_test, y_test)\n",
        "    matrice_conf = comp_confmat(y_test,results)\n",
        "    precision = precision_globale(matrice_conf)\n",
        "    recall = rappel_globale(matrice_conf)\n",
        "    fscore = f_mesure_globale(matrice_conf)\n",
        "    accuracy = accuracy_score(y_test, results)\n",
        "    print(\"IMPLEMENTATION ALGORITHME LDA SANS BIBLIOTHEQUE:\")\n",
        "    print(\"Taux de bonne classification :\", accuracy)\n",
        "    print(\"La pr√©cision :\", precision)\n",
        "    print(\"La rappel :\", recall)\n",
        "    print(\"F-mesure :\", fscore)\n",
        "    print(\"Matrice de confusion LDA: \\n\", matrice_conf)\n",
        "\n",
        "\n",
        "    # QDA SANS BIBLIOTHEQUE\n",
        "    results = QDA_ALGO(X_test, y_test)\n",
        "    matrice_conf = comp_confmat(y_test,results)\n",
        "    precision = precision_globale(matrice_conf)\n",
        "    recall = rappel_globale(matrice_conf)\n",
        "    fscore = f_mesure_globale(matrice_conf)\n",
        "    accuracy = accuracy_score(y_test, results)\n",
        "    print(\"\\n\")\n",
        "    print(\"IMPLEMENTATION ALGORITHME QDA  SANS BIBLIOTHEQUE:\")\n",
        "    print(\"Taux de bonne classification :\", accuracy)\n",
        "    print(\"La pr√©cision :\", precision)\n",
        "    print(\"La rappel :\", recall)\n",
        "    print(\"F-mesure :\", fscore)\n",
        "    #2.3 Matrice de confusion sans biblioth√®que\n",
        "    print(\"Matrice de confusion QDA: \\n\", matrice_conf)\n",
        "\n",
        "    #UTILISATION D'UNE BIBLIOTHEQUE\n",
        "    #2.5 Refaire 2.2 et 2.3 en utilisant une biblioth√®que existante\n",
        "    print(\"\\n\")\n",
        "    print(\"UTILISANT UNE BIBLIOTHEQUE LDA :\")\n",
        "    classifier_bibil = LinearDiscriminantAnalysis() \n",
        "    classifier_bibil.fit(X_train, y_train)\n",
        "    results_b = classifier_bibil.predict(X_test)\n",
        "    # METHODE DE VALIDATION CROIS√âE AVEC BIBLIOTHEQUE(10-fold)\n",
        "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    precision = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='precision_micro').mean()\n",
        "    recall= cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='recall_micro').mean()\n",
        "    f1 = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='f1_micro').mean()\n",
        "    accuracy = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
        "    print(\"Taux de bonne classification :\", accuracy)\n",
        "    print(\"Precision :\", precision)\n",
        "    print(\"Rapelle :\", recall)\n",
        "    print(\"F-mesure :\", f1)\n",
        "    y_pred=classifier_bibil.predict(X_test)\n",
        "    print(\"Matrice de confusion : \\n\",confusion_matrix(y_test,results_b)) \n",
        "    \n",
        "\n",
        "    #UTILISATION D'UNE BIBLIOTHEQUE\n",
        "    #2.5 Refaire 2.2 et 2.3 en utilisant une biblioth√®que existante\n",
        "    print(\"\\n\")\n",
        "    print(\"UTILISANT UNE BIBLIOTHEQUE QDA :\")\n",
        "    classifier_bibil = QuadraticDiscriminantAnalysis() \n",
        "    classifier_bibil.fit(X_train, y_train)\n",
        "    results_b = classifier_bibil.predict(X_test)\n",
        "    # METHODE DE VALIDATION CROIS√âE AVEC BIBLIOTHEQUE(10-fold)\n",
        "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    precision = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='precision_micro').mean()\n",
        "    recall= cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='recall_micro').mean()\n",
        "    f1 = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='f1_micro').mean()\n",
        "    accuracy = cross_val_score(classifier_bibil, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
        "    print(\"Taux de bonne classification :\", accuracy)\n",
        "    print(\"Precision :\", precision)\n",
        "    print(\"Rapelle :\", recall)\n",
        "    print(\"F-mesure :\", f1)\n",
        "    y_pred=classifier_bibil.predict(X_test)\n",
        "    print(\"Matrice de confusion: \\n\",confusion_matrix(y_test,results_b)) \n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOEZjWdEfUES",
        "outputId": "e4c8b55a-7299-41ca-e898-947ba072c6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPLEMENTATION ALGORITHME LDA SANS BIBLIOTHEQUE:\n",
            "Taux de bonne classification : 0.9666666666666667\n",
            "La pr√©cision : 0.9666666666666667\n",
            "La rappel : 0.9666666666666667\n",
            "F-mesure : 0.9666666666666667\n",
            "Matrice de confusion LDA: \n",
            " [[ 8.  0.  0.]\n",
            " [ 0. 10.  1.]\n",
            " [ 0.  0. 11.]]\n",
            "\n",
            "\n",
            "IMPLEMENTATION ALGORITHME QDA  SANS BIBLIOTHEQUE:\n",
            "Taux de bonne classification : 0.8666666666666667\n",
            "La pr√©cision : 0.8666666666666667\n",
            "La rappel : 0.8666666666666667\n",
            "F-mesure : 0.8666666666666667\n",
            "Matrice de confusion QDA: \n",
            " [[ 8.  0.  0.]\n",
            " [ 0.  7.  4.]\n",
            " [ 0.  0. 11.]]\n",
            "\n",
            "\n",
            "UTILISANT UNE BIBLIOTHEQUE LDA :\n",
            "Taux de bonne classification : 0.9916666666666666\n",
            "Precision : 0.9916666666666666\n",
            "Rapelle : 0.9916666666666666\n",
            "F-mesure : 0.9916666666666666\n",
            "Matrice de confusion : \n",
            " [[ 8  0  0]\n",
            " [ 0 10  1]\n",
            " [ 0  1 10]]\n",
            "\n",
            "\n",
            "UTILISANT UNE BIBLIOTHEQUE QDA :\n",
            "Taux de bonne classification : 0.9833333333333332\n",
            "Precision : 0.9833333333333332\n",
            "Rapelle : 0.9833333333333332\n",
            "F-mesure : 0.9833333333333332\n",
            "Matrice de confusion: \n",
            " [[ 8  0  0]\n",
            " [ 0 10  1]\n",
            " [ 0  1 10]]\n"
          ]
        }
      ]
    }
  ]
}